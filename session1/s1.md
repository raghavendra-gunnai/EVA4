1. What Are Channels & Kernels
A. Channels:A channel is an output of an image pixels or another channel  multiplied by a 3x3 kernel. Channels are a set of features useful to generate complex features.  
   Kernels: A kernel is a filter/future detector applied over the channel to reduce/extract the information(edges, shapes, etc).

2. Why should we only (well mostly) use 3x3 Kernels?
A. There are different reasons..
   i - If the kernel is even: If ther kernel size is even, then we don't have axis of symmetry in horizontal/vertical space where as we do have it if kernel is odd (i.e., nxn n is odd)
   ii - If ther kernel is odd and > 3: Nvidia who is leader in GPU, have accelerated the kernel size of 3. We could use other odd numbered kernel size if the image size is too big.

3. How many times do we need to perform 3x3 convolution operation to reach 1x1 from 199x199 (show calculations)?
   Total 100 Calculations
   199 x 199 | 3x3 > 197 x 197
   197 x 197 | 3x3 > 195 x 195
   195 x 195 | 3x3 > 193 x 193
   193x193 | 3x3 > 191x191
   191x191 | 3x3 > 189x189
   189x189 | 3x3 > 187x187
   187x187 | 3x3 > 185x185
   185x185 | 3x3 > 183x183
   183x183 | 3x3 > 181x181
   181x181 | 3x3 > 179x179
   179x179 | 3x3 > 177x177
   177x177 | 3x3 > 175x175
   175x175 | 3x3 > 173x173
   173x173 | 3x3 > 171x171
   171x171 | 3x3 > 169x169
   169x169 | 3x3 > 167x167
   167x167 | 3x3 > 165x165
   165x165 | 3x3 > 163x163
   163x163 | 3x3 > 161x161
   161x161 | 3x3 > 159x159
   159x159 | 3x3 > 157x157
   157x157 | 3x3 > 155x155
   155x155 | 3x3 > 153x153
   153x153 | 3x3 > 151x151
   151x151 | 3x3 > 149x149
   149x149 | 3x3 > 147x147
   147x147 | 3x3 > 145x145
   145x145 | 3x3 > 143x143
   143x143 | 3x3 > 141x141
   141x141 | 3x3 > 139x139
   139x139 | 3x3 > 137x137
   137x137 | 3x3 > 135x135
   135x135 | 3x3 > 133x133
   .
   .
   .
   3x3    | 3x3 > 1x1

4. How are kernels initialized? 
A. Kernels are initialized randomly using random normal distribution with 0 mean and unit standard deviation.. There are different initialization techniques, Xavier initialization, glorot initialization, He Initialization, etc. Further these kernels weights are updated in the backpropogation technique. 

5. What happens during the training of a DNN?
A. initially, The model is being kickstarted with random weights. Then the loss is calculated and the weights are updated as per the loss. Let's say we are implementing Batch Gradient Decent. So, For every batch, the loss is calculated (actual-predicted) and gradient is calculated w.r.t weights and weights are updated accordingly. This process continues till the convergence/total no.of epochs is being run. 
